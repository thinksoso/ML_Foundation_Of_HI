{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "C:\\Users\\zrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\zrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "C:\\Users\\zrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n",
      "C:\\Users\\zrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "C:\\Users\\zrh\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 20 ===== ===== test accuracy is  0.254 ==========\n",
      "========== 40 ===== ===== test accuracy is  0.35 ==========\n",
      "========== 60 ===== ===== test accuracy is  0.482 ==========\n",
      "========== 80 ===== ===== test accuracy is  0.532 ==========\n",
      "========== 100 ===== ===== test accuracy is  0.59 ==========\n",
      "========== 120 ===== ===== test accuracy is  0.656 ==========\n",
      "========== 140 ===== ===== test accuracy is  0.676 ==========\n",
      "========== 160 ===== ===== test accuracy is  0.7 ==========\n",
      "========== 180 ===== ===== test accuracy is  0.724 ==========\n",
      "========== 200 ===== ===== test accuracy is  0.732 ==========\n",
      "========== 220 ===== ===== test accuracy is  0.788 ==========\n",
      "========== 240 ===== ===== test accuracy is  0.798 ==========\n",
      "========== 260 ===== ===== test accuracy is  0.832 ==========\n",
      "========== 280 ===== ===== test accuracy is  0.834 ==========\n",
      "========== 300 ===== ===== test accuracy is  0.828 ==========\n",
      "========== 320 ===== ===== test accuracy is  0.834 ==========\n",
      "========== 340 ===== ===== test accuracy is  0.84 ==========\n",
      "========== 360 ===== ===== test accuracy is  0.862 ==========\n",
      "========== 380 ===== ===== test accuracy is  0.884 ==========\n",
      "========== 400 ===== ===== test accuracy is  0.87 ==========\n",
      "========== 420 ===== ===== test accuracy is  0.884 ==========\n",
      "========== 440 ===== ===== test accuracy is  0.908 ==========\n",
      "========== 460 ===== ===== test accuracy is  0.9 ==========\n",
      "========== 480 ===== ===== test accuracy is  0.89 ==========\n",
      "========== 500 ===== ===== test accuracy is  0.904 ==========\n",
      "========== 520 ===== ===== test accuracy is  0.898 ==========\n",
      "========== 540 ===== ===== test accuracy is  0.91 ==========\n",
      "========== 560 ===== ===== test accuracy is  0.904 ==========\n",
      "========== 580 ===== ===== test accuracy is  0.904 ==========\n",
      "========== 600 ===== ===== test accuracy is  0.912 ==========\n",
      "========== 620 ===== ===== test accuracy is  0.914 ==========\n",
      "========== 640 ===== ===== test accuracy is  0.932 ==========\n",
      "========== 660 ===== ===== test accuracy is  0.932 ==========\n",
      "========== 680 ===== ===== test accuracy is  0.928 ==========\n",
      "========== 700 ===== ===== test accuracy is  0.91 ==========\n",
      "========== 720 ===== ===== test accuracy is  0.912 ==========\n",
      "========== 740 ===== ===== test accuracy is  0.91 ==========\n",
      "========== 760 ===== ===== test accuracy is  0.928 ==========\n",
      "========== 780 ===== ===== test accuracy is  0.914 ==========\n",
      "========== 800 ===== ===== test accuracy is  0.932 ==========\n",
      "========== 820 ===== ===== test accuracy is  0.934 ==========\n",
      "========== 840 ===== ===== test accuracy is  0.93 ==========\n",
      "========== 860 ===== ===== test accuracy is  0.934 ==========\n",
      "========== 880 ===== ===== test accuracy is  0.942 ==========\n",
      "========== 900 ===== ===== test accuracy is  0.942 ==========\n",
      "========== 920 ===== ===== test accuracy is  0.93 ==========\n",
      "========== 940 ===== ===== test accuracy is  0.95 ==========\n",
      "========== 960 ===== ===== test accuracy is  0.94 ==========\n",
      "========== 980 ===== ===== test accuracy is  0.94 ==========\n",
      "========== 1000 ===== ===== test accuracy is  0.948 ==========\n",
      "========== 1020 ===== ===== test accuracy is  0.94 ==========\n",
      "========== 1040 ===== ===== test accuracy is  0.946 ==========\n",
      "========== 1060 ===== ===== test accuracy is  0.942 ==========\n",
      "========== 1080 ===== ===== test accuracy is  0.944 ==========\n",
      "========== 1100 ===== ===== test accuracy is  0.944 ==========\n",
      "========== 1120 ===== ===== test accuracy is  0.952 ==========\n",
      "========== 1140 ===== ===== test accuracy is  0.958 ==========\n",
      "========== 1160 ===== ===== test accuracy is  0.946 ==========\n",
      "========== 1180 ===== ===== test accuracy is  0.942 ==========\n",
      "========== 20 ===== ===== test accuracy is  0.948 ==========\n",
      "========== 40 ===== ===== test accuracy is  0.956 ==========\n",
      "========== 60 ===== ===== test accuracy is  0.942 ==========\n",
      "========== 80 ===== ===== test accuracy is  0.954 ==========\n",
      "========== 100 ===== ===== test accuracy is  0.942 ==========\n",
      "========== 120 ===== ===== test accuracy is  0.948 ==========\n",
      "========== 140 ===== ===== test accuracy is  0.954 ==========\n",
      "========== 160 ===== ===== test accuracy is  0.954 ==========\n",
      "========== 180 ===== ===== test accuracy is  0.936 ==========\n",
      "========== 200 ===== ===== test accuracy is  0.952 ==========\n",
      "========== 220 ===== ===== test accuracy is  0.946 ==========\n",
      "========== 240 ===== ===== test accuracy is  0.958 ==========\n",
      "========== 260 ===== ===== test accuracy is  0.96 ==========\n",
      "========== 280 ===== ===== test accuracy is  0.952 ==========\n",
      "========== 300 ===== ===== test accuracy is  0.948 ==========\n",
      "========== 320 ===== ===== test accuracy is  0.944 ==========\n",
      "========== 340 ===== ===== test accuracy is  0.96 ==========\n",
      "========== 360 ===== ===== test accuracy is  0.962 ==========\n",
      "========== 380 ===== ===== test accuracy is  0.952 ==========\n",
      "========== 400 ===== ===== test accuracy is  0.954 ==========\n",
      "========== 420 ===== ===== test accuracy is  0.954 ==========\n",
      "========== 440 ===== ===== test accuracy is  0.958 ==========\n",
      "========== 460 ===== ===== test accuracy is  0.96 ==========\n",
      "========== 480 ===== ===== test accuracy is  0.952 ==========\n",
      "========== 500 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 520 ===== ===== test accuracy is  0.974 ==========\n",
      "========== 540 ===== ===== test accuracy is  0.952 ==========\n",
      "========== 560 ===== ===== test accuracy is  0.972 ==========\n",
      "========== 580 ===== ===== test accuracy is  0.96 ==========\n",
      "========== 600 ===== ===== test accuracy is  0.954 ==========\n",
      "========== 620 ===== ===== test accuracy is  0.96 ==========\n",
      "========== 640 ===== ===== test accuracy is  0.954 ==========\n",
      "========== 660 ===== ===== test accuracy is  0.958 ==========\n",
      "========== 680 ===== ===== test accuracy is  0.956 ==========\n",
      "========== 700 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 720 ===== ===== test accuracy is  0.96 ==========\n",
      "========== 740 ===== ===== test accuracy is  0.958 ==========\n",
      "========== 760 ===== ===== test accuracy is  0.964 ==========\n",
      "========== 780 ===== ===== test accuracy is  0.962 ==========\n",
      "========== 800 ===== ===== test accuracy is  0.958 ==========\n",
      "========== 820 ===== ===== test accuracy is  0.964 ==========\n",
      "========== 840 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 860 ===== ===== test accuracy is  0.958 ==========\n",
      "========== 880 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 900 ===== ===== test accuracy is  0.954 ==========\n",
      "========== 920 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 940 ===== ===== test accuracy is  0.968 ==========\n",
      "========== 960 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 980 ===== ===== test accuracy is  0.962 ==========\n",
      "========== 1000 ===== ===== test accuracy is  0.964 ==========\n",
      "========== 1020 ===== ===== test accuracy is  0.964 ==========\n",
      "========== 1040 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 1060 ===== ===== test accuracy is  0.974 ==========\n",
      "========== 1080 ===== ===== test accuracy is  0.962 ==========\n",
      "========== 1100 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 1120 ===== ===== test accuracy is  0.974 ==========\n",
      "========== 1140 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 1160 ===== ===== test accuracy is  0.968 ==========\n",
      "========== 1180 ===== ===== test accuracy is  0.968 ==========\n",
      "========== 20 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 40 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 60 ===== ===== test accuracy is  0.964 ==========\n",
      "========== 80 ===== ===== test accuracy is  0.974 ==========\n",
      "========== 100 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 120 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 140 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 160 ===== ===== test accuracy is  0.978 ==========\n",
      "========== 180 ===== ===== test accuracy is  0.976 ==========\n",
      "========== 200 ===== ===== test accuracy is  0.972 ==========\n",
      "========== 220 ===== ===== test accuracy is  0.972 ==========\n",
      "========== 240 ===== ===== test accuracy is  0.954 ==========\n",
      "========== 260 ===== ===== test accuracy is  0.974 ==========\n",
      "========== 280 ===== ===== test accuracy is  0.972 ==========\n",
      "========== 300 ===== ===== test accuracy is  0.964 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 320 ===== ===== test accuracy is  0.978 ==========\n",
      "========== 340 ===== ===== test accuracy is  0.964 ==========\n",
      "========== 360 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 380 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 400 ===== ===== test accuracy is  0.968 ==========\n",
      "========== 420 ===== ===== test accuracy is  0.964 ==========\n",
      "========== 440 ===== ===== test accuracy is  0.96 ==========\n",
      "========== 460 ===== ===== test accuracy is  0.98 ==========\n",
      "========== 480 ===== ===== test accuracy is  0.962 ==========\n",
      "========== 500 ===== ===== test accuracy is  0.972 ==========\n",
      "========== 520 ===== ===== test accuracy is  0.978 ==========\n",
      "========== 540 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 560 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 580 ===== ===== test accuracy is  0.972 ==========\n",
      "========== 600 ===== ===== test accuracy is  0.966 ==========\n",
      "========== 620 ===== ===== test accuracy is  0.968 ==========\n",
      "========== 640 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 660 ===== ===== test accuracy is  0.976 ==========\n",
      "========== 680 ===== ===== test accuracy is  0.98 ==========\n",
      "========== 700 ===== ===== test accuracy is  0.968 ==========\n",
      "========== 720 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 740 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 760 ===== ===== test accuracy is  0.974 ==========\n",
      "========== 780 ===== ===== test accuracy is  0.964 ==========\n",
      "========== 800 ===== ===== test accuracy is  0.972 ==========\n",
      "========== 820 ===== ===== test accuracy is  0.978 ==========\n",
      "========== 840 ===== ===== test accuracy is  0.976 ==========\n",
      "========== 860 ===== ===== test accuracy is  0.974 ==========\n",
      "========== 880 ===== ===== test accuracy is  0.976 ==========\n",
      "========== 900 ===== ===== test accuracy is  0.976 ==========\n",
      "========== 920 ===== ===== test accuracy is  0.962 ==========\n",
      "========== 940 ===== ===== test accuracy is  0.972 ==========\n",
      "========== 960 ===== ===== test accuracy is  0.974 ==========\n",
      "========== 980 ===== ===== test accuracy is  0.968 ==========\n",
      "========== 1000 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 1020 ===== ===== test accuracy is  0.974 ==========\n",
      "========== 1040 ===== ===== test accuracy is  0.974 ==========\n",
      "========== 1060 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 1080 ===== ===== test accuracy is  0.972 ==========\n",
      "========== 1100 ===== ===== test accuracy is  0.978 ==========\n",
      "========== 1120 ===== ===== test accuracy is  0.97 ==========\n",
      "========== 1140 ===== ===== test accuracy is  0.976 ==========\n",
      "========== 1160 ===== ===== test accuracy is  0.976 ==========\n",
      "========== 1180 ===== ===== test accuracy is  0.974 ==========\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "learning_rate = 1e-4\n",
    "keep_prob_rate = 0.7 #\n",
    "max_epoch = 3\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "DOWNLOAD_MNIST = False\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    # not mnist dir or mnist is empyt dir\n",
    "    DOWNLOAD_MNIST = True\n",
    "\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(root='./mnist/',train=True, transform=torchvision.transforms.ToTensor(), download=DOWNLOAD_MNIST,)\n",
    "train_loader = Data.DataLoader(dataset = train_data ,batch_size= BATCH_SIZE ,shuffle= True)\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(root = './mnist/',train = False)\n",
    "test_x = Variable(torch.unsqueeze(test_data.test_data,dim  = 1),volatile = True).type(torch.FloatTensor)[:500]/255.\n",
    "test_y = test_data.test_labels[:500].numpy()\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d( # ???\n",
    "                # patch 5 * 5 ; 1  in channels ; 32 out channels ; ; stride is 1\n",
    "                # padding style is same(that means the convolution opration's input and output have the same size)\n",
    "                in_channels=1      ,  \n",
    "                out_channels=32     ,\n",
    "                kernel_size=5      ,\n",
    "                stride=1           ,\n",
    "                padding=2          ,\n",
    "            ),\n",
    "            nn.ReLU(),        # activation function\n",
    "            nn.MaxPool2d(2),  # pooling operation\n",
    "        )\n",
    "        self.conv2 = nn.Sequential( # ???\n",
    "            # line 1 : convolution function, patch 5*5 , 32 in channels ;64 out channels; padding style is same; stride is 1\n",
    "            # line 2 : choosing your activation funciont\n",
    "            # line 3 : pooling operation function.\n",
    "            nn.Conv2d( # ???\n",
    "                in_channels=32      ,  \n",
    "                out_channels=64     ,\n",
    "                kernel_size=5      ,\n",
    "                stride=1           ,\n",
    "                padding=2          ,\n",
    "            ),\n",
    "            nn.ReLU(),        # activation function\n",
    "            nn.MaxPool2d(2),  # pooling operation            \n",
    "         \n",
    "\n",
    "        )\n",
    "        self.out1 = nn.Linear( 7*7*64 , 1024 , bias= True)   # full connection layer one\n",
    "\n",
    "        self.dropout = nn.Dropout(keep_prob_rate)\n",
    "        self.out2 = nn.Linear(1024,10,bias=True)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0),-1)  # flatten the output of coonv2 to (batch_size ,32 * 7 * 7)    # ???\n",
    "        out1 = self.out1(x)\n",
    "        out1 = F.relu(out1)\n",
    "        out1 = self.dropout(out1)\n",
    "        out2 = self.out2(out1)\n",
    "        output = F.softmax(out2)\n",
    "        return output\n",
    "\n",
    "\n",
    "def test(cnn):\n",
    "    global prediction\n",
    "    y_pre = cnn(test_x)\n",
    "    _,pre_index= torch.max(y_pre,1)\n",
    "    pre_index= pre_index.view(-1)\n",
    "    prediction = pre_index.data.numpy()\n",
    "    correct  = np.sum(prediction == test_y)\n",
    "    return correct / 500.0\n",
    "\n",
    "\n",
    "def train(cnn):\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate )\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    for epoch in range(max_epoch):\n",
    "        for step, (x_, y_) in enumerate(train_loader):\n",
    "            x ,y= Variable(x_),Variable(y_)\n",
    "            output = cnn(x)  \n",
    "            loss = loss_func(output,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step != 0 and step % 20 ==0:\n",
    "                print(\"=\" * 10,step,\"=\"*5,\"=\"*5, \"test accuracy is \",test(cnn) ,\"=\" * 10 )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cnn = CNN()\n",
    "    train(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
