{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3dfcad-7857-4ba6-82a6-a6fe790c7908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考：zhangxiangxu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d5d542-ba32-40ec-9b0d-b0f848b6e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02a8a9-774c-4223-bc75-ced835f5f7c3",
   "metadata": {},
   "source": [
    "# 1 读入数据并预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8455152-8442-43f0-abb1-60b2590c7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.tsv.zip', sep='\\t')\n",
    "test = pd.read_csv('data/test.tsv.zip', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce64ee48-ded9-4a22-8ec0-8bed1828aeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c38232d6-3ec4-446d-a586-56f9b6b0d1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45710285-016f-4724-90c8-fc77c9b631ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a04361c9-d59b-431b-bbde-40562be57010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50dfe99-e026-40a8-ba89-b3bd4674932b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'分布情况'}, xlabel='Sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "ax = plt.axes()\n",
    "ax.set_title('分布情况')\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "sns.countplot(x=train.Sentiment, data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2f50e53-5d3c-440e-b946-d62c84f5cca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b712417-a0eb-4185-a89d-4e291333e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maketrans&translate的使用：  https://blog.csdn.net/jpch89/article/details/86759980\n",
    "train['Phrase1'] = train.Phrase.apply(lambda x: x.translate(str.maketrans('','', string.punctuation)).lower())\n",
    "#str.maketrans('','', string.punctuation))使用了三个参数，前两个参数是转换，这里没有使用\n",
    "#第三个参数中出现的字符将被转为None\n",
    "test['Phrase1'] = test.Phrase.apply(lambda x: x.translate(str.maketrans('','', string.punctuation)).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd0a72c4-4100-4bdf-9bd4-e0d81c707559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>a series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment                                            Phrase1  \n",
       "0          1  a series of escapades demonstrating the adage ...  \n",
       "1          2  a series of escapades demonstrating the adage ...  \n",
       "2          2                                           a series  \n",
       "3          2                                                  a  \n",
       "4          2                                             series  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981f35c6-3b1a-4f02-9df1-eda2f5012971",
   "metadata": {},
   "source": [
    "# 2 文本特征表示并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44d423a2-1580-4dc6-85d8-6a486ab06fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(series, c):\n",
    "    \"\"\"\n",
    "    输入一个series，内容为整数，转为独热向量矩阵，维度为c*样本数\n",
    "    参数：\n",
    "    series：df中包含Sentiment的一列\n",
    "    c：类别数，int\n",
    "    返回：\n",
    "    Y：独热向量矩阵，c*样本数\n",
    "    \"\"\"\n",
    "    num = series.shape[0]\n",
    "    Y = np.eye(c)[np.array(series).reshape(-1)].T\n",
    "    assert Y.shape == (c, num)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d38c7d62-096f-45b5-9d56-520829410353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(df):\n",
    "    \"\"\"\n",
    "    输入数据df，建立词袋，给数据df增添一个新的列Set_of_word，里面包含该样本中所含有的词汇，同时返回一个包含所有词汇的列表\n",
    "    \"\"\"\n",
    "    df['Set_of_word'] = df.Phrase1.apply(lambda x: set(x.split()))\n",
    "    bag_of_word = set()\n",
    "    for _, value in df.Set_of_word.items():\n",
    "        bag_of_word |= value\n",
    "    return list(bag_of_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "383d4d0b-e940-42d9-99ae-898ad593b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(x, n):\n",
    "    \"\"\"\n",
    "    用于create_couple_dictionary生成词组\n",
    "    \"\"\"\n",
    "    temp = [x.split()[i: i + n] for i in range(len(x.split()) - n + 1)]\n",
    "    res = tuple(t for t in set(tuple(_) for _ in temp))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "062188fc-74de-460f-8b41-f74b0bae43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_couple_dictionary(df, n):\n",
    "    \"\"\"\n",
    "    输入数据df，建立词组袋，给数据df增添一个新的列Set_of_word_couple，里面包含该样本中所含有的词组，同时返回一个包含所有词组的列表\n",
    "    参数：\n",
    "    df：DataFrame, 大小为156060*5，包含所有数据\n",
    "    n：词组的个数\n",
    "    \"\"\"\n",
    "    df['Set_of_word_couple'] = df.Phrase1.apply(function, n=n)\n",
    "    bag_of_word_couple = set()\n",
    "    for _, value in df.Set_of_word_couple.items():\n",
    "        bag_of_word_couple |= set(value)\n",
    "    return list(bag_of_word_couple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ff9e8e0-192f-4ccf-91be-6a12c5ea57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_word(df):\n",
    "    \"\"\"\n",
    "    根据数据表格，生成包含所有词的列表,对于每行数据，根据其中包含的词构建词袋向量\n",
    "    参数：\n",
    "    df：DataFrame, 大小为156060*5，包含所有数据，至少有五列：PhraseId，SentenceId，Phrase，Sentiment，Phrase1，运行结束后增加一列Set_of_word\n",
    "    返回：\n",
    "    word_matrix：包含词袋向量的矩阵，维度为词汇量*样本量\n",
    "    word_to_index：一个词对→索引的字典\n",
    "    index_to_word：一个索引→词对的字典\n",
    "    \"\"\"\n",
    "    amount, _ = df.shape\n",
    "    bag_of_word = create_dictionary(df)  # 词袋列表，同时给df增加一个新的列Set_of_word\n",
    "    dimension = len(bag_of_word)\n",
    "    # 设置一个矩阵，用来盛放每条数据的词袋向量，顺序与df一致，大小为词汇数量*样本数量\n",
    "    word_matrix = np.zeros((dimension, amount), dtype='i1') # int8\n",
    "    # 遍历数据，填充word_matrix，对于每一行的样本，先将其按照单词拆为列表，然后找到每个单词在word_matrix中的位置，将其数值加1\n",
    "    word_to_index = {}  # 一个词汇→索引的字典\n",
    "    index_to_word = {}  # 一个索引→词汇的字典\n",
    "    for row in df.itertuples():\n",
    "        index = getattr(row, 'Index')\n",
    "        temp_list = getattr(row, 'Phrase1').split()  # 得到的是列表类型\n",
    "        for word in temp_list:\n",
    "            # 确定单词在词袋中的位置\n",
    "            if word_to_index.get(word, -1) < 0:\n",
    "                position = bag_of_word.index(word)\n",
    "                word_to_index[word] = position\n",
    "                index_to_word[position] = word\n",
    "            else:\n",
    "                position = word_to_index.get(word, -1)\n",
    "            # 修改word_matrix\n",
    "            word_matrix[position][index] += 1\n",
    "    assert word_matrix.shape == (len(bag_of_word), df.shape[0])\n",
    "    return word_matrix, word_to_index, index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36e8eb36-ac37-4998-890b-7e7cd8b15426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(df, n):\n",
    "    \"\"\"\n",
    "     根据数据表格，生成包含所有词组的列表,对于每行数据，根据其中包含的词组构建词袋向量\n",
    "     参数：\n",
    "     df：DataFrame, 大小为156060*5，包含所有数据，至少有五列：PhraseId，SentenceId，Phrase，Sentiment，Phrase1，运行结束后增加一列Set_of_word_couple\n",
    "     n：每个组合中包含词的数量\n",
    "     返回：\n",
    "     word_matrix：包含词袋向量的矩阵，维度为词汇量*样本量\n",
    "     couple_to_index：一个词对→索引的字典\n",
    "     index_to_couple：一个索引→词对的字典\n",
    "    \"\"\"\n",
    "    amount, _ = df.shape\n",
    "    bag_of_word = create_couple_dictionary(df, n=2)  # 词袋列表，同时给df增加一个新的列Set_of_word\n",
    "    dimension = len(bag_of_word)\n",
    "    # 设置一个矩阵，用来盛放每条数据的词袋向量，顺序与df一致，大小为词汇数量*样本数量\n",
    "    word_matrix = np.zeros((dimension, amount), dtype='i1')\n",
    "    # 遍历数据，填充word_matrix，对于每一行的样本，先将其按照单词拆为列表，然后找到每个单词在word_matrix中的位置，将其数值加1\n",
    "    couple_to_index = {}  # 一个词汇→索引的字典\n",
    "    index_to_couple = {}  # 一个索引→词汇的字典\n",
    "    for row in df.itertuples():\n",
    "        index = getattr(row, 'Index')\n",
    "        temp = getattr(row, 'Phrase1').split()  \n",
    "        temp_list = [tuple(temp[i: i + n]) for i in range(len(temp) - n + 1)]# 得到的是列表类型\n",
    "        for couple in temp_list:\n",
    "            # 确定单词在词袋中的位置\n",
    "            if couple_to_index.get(couple, -1) < 0:\n",
    "                position = bag_of_word.index(couple)\n",
    "                couple_to_index[couple] = position\n",
    "                index_to_couple[position] = couple\n",
    "            else:\n",
    "                position = couple_to_index.get(couple, -1)\n",
    "            # 修改word_matrix\n",
    "            word_matrix[position][index] += 1\n",
    "        if index % 100 == 0:\n",
    "            print(f'{index/amount * 100:.2f}%', end='\\r')\n",
    "    assert word_matrix.shape == (len(bag_of_word), df.shape[0])\n",
    "    return word_matrix, couple_to_index, index_to_couple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "891faaf6-5a22-46d8-9db2-a2a638facd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select(X, threshold=.8*(1-.8)):\n",
    "    \"\"\"\n",
    "    删除方差较小的特征\n",
    "    参数：\n",
    "    X：array，d*n\n",
    "    threshold：标量，阈值\n",
    "    返回：\n",
    "    X_selected：array,选择后的特征\n",
    "    idx: 删除的下标\n",
    "    \"\"\"\n",
    "    d, n = X.shape\n",
    "    var = np.var(X, axis=1).reshape((d, 1))\n",
    "    mask = var > threshold\n",
    "    temp = mask * X\n",
    "    idx = np.argwhere(np.all(temp[..., :] == 0, axis=1))\n",
    "    X_selected = np.delete(X, idx, axis=0)\n",
    "    \n",
    "    return X_selected, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41d9b4e7-7a49-44fd-814d-cdb83fdeeb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22096991  1.18425384 -1.85350399  0.07914185]\n",
      " [-0.62877822 -1.92374444 -2.66443713 -0.65221616]\n",
      " [ 1.52419647  0.70317894 -1.24320864  0.36069842]\n",
      " [-2.43249082  0.25646575  0.34521819 -0.33455549]\n",
      " [ 0.50673148 -0.95581905  1.34438223 -1.52558943]]\n",
      "\n",
      "[[-0.22096991  1.18425384 -1.85350399  0.07914185]\n",
      " [-0.62877822 -1.92374444 -2.66443713 -0.65221616]\n",
      " [ 1.52419647  0.70317894 -1.24320864  0.36069842]\n",
      " [-2.43249082  0.25646575  0.34521819 -0.33455549]\n",
      " [ 0.50673148 -0.95581905  1.34438223 -1.52558943]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(5,4)\n",
    "b, idx = feature_select(a, 0.7)\n",
    "print(a, end='\\n\\n')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b349132-24f1-4ec2-a8a4-f838f490343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证词袋\n",
    "data = train\n",
    "word_matrix_raw, word_to_index, index_to_word = bag_of_word(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "599b2d1f-ea5a-4cba-8486-6b3d45d906b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16403, 156060)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_matrix_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6ed1197-f816-437d-970b-a967972e9cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 156060)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征选择\n",
    "word_matrix, idx = feature_select(word_matrix_raw, 0.001)\n",
    "word_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90f28e1a-486b-439f-89f2-d793a533631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打乱样本\n",
    "Y = convert_to_one_hot(data.Sentiment, 5)\n",
    "np.random.seed(1)\n",
    "permutation = np.random.permutation(word_matrix.shape[1])\n",
    "Y_shuffle = Y[:, permutation]\n",
    "word_matrix_shuffle = word_matrix[:, permutation]\n",
    "\n",
    "# 划分训练集、验证集\n",
    "split1 = int(0.7 * word_matrix.shape[1])\n",
    "split2 = int(0.85 * word_matrix.shape[1])\n",
    "train_X = word_matrix_shuffle[:, 0: split1]\n",
    "train_Y = Y_shuffle[:, 0: split1]\n",
    "valid_X = word_matrix_shuffle[:, split1: split2]\n",
    "valid_Y = Y_shuffle[:, split1: split2]\n",
    "test_X = word_matrix_shuffle[:, split2:]\n",
    "test_Y = Y_shuffle[:, split2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ac53ab0-63fb-4861-8dd5-079062644234",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('.\\data\\matrix_bag_of_word_filter.npz', train_X, train_Y, valid_X, valid_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b66d8-f33f-4ab5-82c2-837fa074d11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵填充结束，开始打乱\n"
     ]
    }
   ],
   "source": [
    "# 验证ngram\n",
    "data = train\n",
    "word_matrix, couple_to_index, index_to_couple = n_gram(data, 2)\n",
    "Y = convert_to_one_hot(data.Sentiment, 5)\n",
    "print(\"矩阵填充结束，开始打乱\")\n",
    "# 打乱样本\n",
    "permutation = np.random.permutation(word_matrix.shape[1])\n",
    "word_matrix_shuffle = word_matrix[:, permutation]\n",
    "Y_shuffle = Y[:, permutation]\n",
    "print(\"打乱完毕，开始划分数据\")\n",
    "# 划分训练集、验证集\n",
    "split1 = int(0.7 * word_matrix.shape[1])\n",
    "split2 = int(0.85 * word_matrix.shape[1])\n",
    "train_X = word_matrix_shuffle[:, 0: split1]\n",
    "train_Y = Y_shuffle[:, 0: split1]\n",
    "valid_X = word_matrix_shuffle[:, split1: split2]\n",
    "valid_Y = Y_shuffle[:, split1: split2]\n",
    "test_X = word_matrix_shuffle[:, split2:]\n",
    "test_Y = Y_shuffle[:, split2:]\n",
    "\n",
    "\n",
    "np.savez('.\\data\\matrix_n_gram_2.npz', train_X, train_Y, valid_X, valid_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137dec48-12ec-4447-9a5d-24e86dd5c91e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c02bfb-b9f6-45cd-840e-782a56ba9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算softmax\n",
    "def softmax(X):\n",
    "    \"\"\"\n",
    "    计算softmax值\n",
    "    :param X: array\n",
    "    :return: s：array，float32，维度与X相同\n",
    "    \"\"\"\n",
    "    s = np.exp(X) / np.sum(np.exp(X), axis=0)\n",
    "    assert s.shape == X.shape\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75440e03-2271-4996-929d-8ea4ff634c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化\n",
    "def parameter_normalize(c, d):\n",
    "    \"\"\"\n",
    "    初始化权重W（d * c），b（c * 1)\n",
    "    参数：\n",
    "    d：维度\n",
    "    n：维度\n",
    "    c：种类\n",
    "    \n",
    "    返回：\n",
    "    W，b\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    W = np.random.randn(d, c)\n",
    "    b = np.zeros((c, 1))\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5fd9b7-2ae8-48c9-81c6-27cd646379cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建mini_batch\n",
    "def create_mini_batches(X, Y, batch_size, seed):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    X：输入, d * n\n",
    "    Y：标签, c * n\n",
    "    batch_size：大小，标量\n",
    "    seed：随机种子，标量\n",
    "    \n",
    "    返回：\n",
    "    mini_batches：包含mini_batch的列表，内部是（mini_batch_X, mini_batch_Y）\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    mini_batches = []\n",
    "    num_of_batches = int(n / batch_size)\n",
    "    for k in range(0, num_of_batches):\n",
    "        mini_batch_X = X[:, k * batch_size: (k + 1) * batch_size]\n",
    "        mini_batch_Y = Y[:, k * batch_size: (k + 1) * batch_size]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    if n % num_of_batches != 0:\n",
    "        mini_batch_X = X[:, num_of_batches * batch_size:]\n",
    "        mini_batch_Y = Y[:, num_of_batches * batch_size:]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774ef55-69ae-4b22-9f70-781c064ef50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向传播\n",
    "def forward(X, parameter, cache):\n",
    "    \"\"\"\n",
    "    执行前向传播，Z = W.T*X + b\n",
    "    :param X: 输入，array，dimension * batch_size\n",
    "    :param parameter：包含参数W，b的字典\n",
    "        W: 权重矩阵，array，d * c\n",
    "        b: 偏置，array，c * 1\n",
    "    :param cache: 盛放Z，Y_hat的字典\n",
    "    \n",
    "    :return: cache：包含Z，Y_hat的字典\n",
    "    \"\"\"\n",
    "    \n",
    "    W = parameter['W']\n",
    "    b = parameter['b']\n",
    "    \n",
    "    Z = np.dot(W.T, X) + b\n",
    "    Y_hat = softmax(Z)\n",
    "    \n",
    "    cache['Z'] = Z\n",
    "    cache['Y_hat'] = Y_hat\n",
    "    assert Z.shape == (W.shape[1], X.shape[1])\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441d45a-bd53-4d11-b489-32acb44b5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算损失\n",
    "def compute_loss(Y, Y_hat, lamda, parameter):\n",
    "    \"\"\"\n",
    "    计算损失\n",
    "    :param Y_hat: array，预测值，c * batch_size\n",
    "    :param Y: array，标签，one_hot矩阵，c * batch_size\n",
    "    :param parameter:包含参数W，b的字典\n",
    "    :return: L，标量\n",
    "    \"\"\"\n",
    "    W = parameter['W']\n",
    "#     Y_hat = cache['Y_hat']\n",
    "    \n",
    "    n = Y.shape[1]\n",
    "    l = - np.sum(Y * np.log(Y_hat), axis=0)\n",
    "    # 加入正则项\n",
    "    loss = np.sum(l) / n + 1 / 2 / n * lamda * np.square(np.linalg.norm(W))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f7d30-a001-4fa7-be31-574540002ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算梯度\n",
    "def backward(X, Y, cache):\n",
    "    \"\"\"\n",
    "    计算梯度\n",
    "    cache：包含参数Z，Y_hat的字典\n",
    "    X: array, float, d * n\n",
    "    Y: array, float, c * n\n",
    "    \n",
    "    return：一个包含梯度dW,db的字典，维度与W，b相同\n",
    "    \"\"\"\n",
    "    Y_hat = cache['Y_hat']\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    # 计算梯度\n",
    "    dW = - np.dot(X, (Y - Y_hat).T) / n\n",
    "    db = - np.sum((Y - Y_hat), axis=1) / n\n",
    "    \n",
    "    gradient = {}\n",
    "    gradient['dW'] = dW\n",
    "    gradient['db'] = db\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75e90a-f5e9-4378-8f42-dc9266df6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数更新\n",
    "def update_gradient(parameter, gradient, learning_rate, lamda, belta1, belta2, epsilon, t, n, opt='SGD'):\n",
    "    \"\"\"\n",
    "    反向传播\n",
    "    参数：\n",
    "    parameter：包含参数W，b, m_W, v_W, m_b, v_b的字典\n",
    "        W: 权重矩阵，float，d * c\n",
    "        b：偏置，float，c * 1\n",
    "    gradient：包含梯度的字典\n",
    "    learning_rate：学习率\n",
    "    lamda：正则化系数\n",
    "    #t: 当前进行下降的次数\n",
    "    \n",
    "    返回：\n",
    "    parameter：包含参数W，b的字典\n",
    "    \"\"\"\n",
    "    dW = gradient['dW']\n",
    "    db = gradient['db']\n",
    "    W = parameter['W']\n",
    "    b = parameter['b']\n",
    "    m_W = parameter['m_W']\n",
    "    v_W = parameter['v_W']\n",
    "    m_b = parameter['m_b']\n",
    "    v_b = parameter['v_b']\n",
    "    c = W.shape[1]\n",
    "    d = W.shape[0]\n",
    "    n = W.shape[1]\n",
    "    dW = dW.reshape((d, c))\n",
    "    db = db.reshape((c, 1))\n",
    "#     print(\"开始\")\n",
    "#     print(b.shape,db.shape)\n",
    "    if opt == 'Adam':\n",
    "        # 更新\n",
    "        m_W = belta1 * m_W + (1 - belta1) * dW\n",
    "        v_W = belta2 * v_W + (1 - belta2) * np.square(dW)\n",
    "        m_W_hat = m_W / (1 - np.power(belta1, t))\n",
    "        v_W_hat = v_W / (1 - np.power(belta2, t))\n",
    "        W = W - np.multiply(learning_rate / (np.sqrt(v_W_hat) + epsilon),  m_W_hat)\n",
    "\n",
    "        m_b = belta1 * m_b + (1 - belta1) * db\n",
    "        v_b = belta2 * v_b + (1 - belta2) * np.square(db)\n",
    "        m_b_hat = m_b / (1 - np.power(belta1, t))\n",
    "        v_b_hat = v_b / (1 - np.power(belta2, t))\n",
    "        b = b - np.multiply(learning_rate / (np.sqrt(v_b_hat) + epsilon),  m_b_hat)\n",
    "    elif opt == 'SGD':\n",
    "        W = W - learning_rate * (dW + 1 / n * lamda * W)\n",
    "        b = b - learning_rate * (db + 1 / n * lamda * b)\n",
    "    assert W.shape == dW.shape\n",
    "#     print(b.shape, db.shape)\n",
    "    assert b.shape == db.shape\n",
    "    \n",
    "    parameter['W'] = W\n",
    "    parameter['b'] = b\n",
    "    parameter['m_W'] = m_W\n",
    "    parameter['v_W'] = v_W\n",
    "    parameter['m_b'] = m_b\n",
    "    parameter['v_b'] = v_b\n",
    "    \n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b22515-0c92-474f-a156-04e32b51eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_data, test_data, num_epochs=1000, batch_size=64, learning_rate=0.001, belta1 = 0.9, belta2 = 0.999, epsilon = 1e-8, lamda=0.1, opt='SGD', if_print=True):\n",
    "    \"\"\"\n",
    "    进行训练\n",
    "    参数：\n",
    "    X：训练数据\n",
    "    Y：标签\n",
    "    epoch：训练次数\n",
    "    batch_size：batch大小\n",
    "    learning_rate：学习率\n",
    "    lamda：正则化系数\n",
    "    \"\"\"\n",
    "    X = train_data[0]\n",
    "    Y = train_data[1]\n",
    "    \n",
    "    test_X = test_data[0]\n",
    "    test_Y = test_data[1]\n",
    "    \n",
    "    d = X.shape[0]\n",
    "    c = Y.shape[0]\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    # 初始化参数\n",
    "    W, b = parameter_normalize(c, d)\n",
    "    m_W = 0\n",
    "    v_W = 0\n",
    "    m_b = 0\n",
    "    v_b = 0\n",
    "    parameter = {}\n",
    "    cache = {}\n",
    "    gradient = {}\n",
    "    parameter['W'] = W\n",
    "    parameter['b'] = b\n",
    "    parameter['m_W'] = m_W\n",
    "    parameter['v_W'] = v_W\n",
    "    parameter['m_b'] = m_b\n",
    "    parameter['v_b'] = v_b\n",
    "    \n",
    "    # 创建mini_batch\n",
    "    mini_batches = create_mini_batches(X, Y, batch_size, seed=1)\n",
    "    t = 0\n",
    "    for i in range(num_epochs):\n",
    "        seed = 0\n",
    "        np.random.seed(seed)\n",
    "        permutation = np.random.permutation(len(mini_batches))\n",
    "#         print(permutation)\n",
    "        mini_batches = np.array(mini_batches, dtype=object)[permutation]\n",
    "        for mini_batch in mini_batches:\n",
    "            t += 1\n",
    "            mini_batch_X, mini_batch_Y = mini_batch\n",
    "            cache = forward(mini_batch_X, parameter, cache)  # 包含Z，Y_hat\n",
    "            Y_hat = cache['Y_hat']\n",
    "            loss = compute_loss(mini_batch_Y, Y_hat, lamda=lamda, parameter=parameter)\n",
    "            gradient = backward(mini_batch_X, mini_batch_Y, cache)  # 包含dW，db\n",
    "            parameter = update_gradient(parameter, gradient, learning_rate=learning_rate, belta1 = belta1, belta2 = belta2, epsilon = epsilon, lamda=lamda, n=mini_batch_X.shape[1], t=t, opt=opt)\n",
    "            \n",
    "        seed += 1\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            \n",
    "            losses.append(loss)\n",
    "            Y_hat = forward(X, parameter, cache)['Y_hat']\n",
    "            preds = np.equal(Y_hat, np.max(Y_hat, axis=0))\n",
    "            true = Y\n",
    "            correct_prediction = np.equal(preds, true)\n",
    "            \n",
    "            \n",
    "            \n",
    "            test_Y_hat = forward(test_X, parameter, cache)['Y_hat']\n",
    "            preds = np.equal(test_Y_hat, np.max(test_Y_hat, axis=0))\n",
    "            true = test_Y\n",
    "            correct_prediction = np.equal(preds, true)\n",
    "            test_loss = compute_loss(true, test_Y_hat, lamda=lamda, parameter=parameter)\n",
    "            test_losses.append(test_loss)\n",
    "            if if_print:\n",
    "                print(f\"已运行{i}次，当前损失为：\" + str(loss), end=', ')\n",
    "                print(f\"当前训练集准确率为：{np.mean(correct_prediction) * 100:.2f}%\")\n",
    "                print(f\"当前测试集损失为：{test_loss}\", end=', ')\n",
    "                print(f\"当前测试集准确率为：{np.mean(correct_prediction) * 100:.2f}%\")\n",
    "    W = parameter['W']\n",
    "    b = parameter['b']\n",
    "    \n",
    "    return parameter, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5533f-302e-48d1-9e00-2a079a5679c7",
   "metadata": {},
   "source": [
    "# 4 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df5dbb-f34f-4d21-9f3d-9d56003f9b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入预处理好的数据\n",
    "# 词袋\n",
    "matrix = np.load('.\\data\\matrix_bag_of_word.npz')\n",
    "\n",
    "train_X = matrix['arr_0']\n",
    "train_Y = matrix['arr_1']\n",
    "valid_X = matrix['arr_2']\n",
    "valid_Y = matrix['arr_3']\n",
    "test_X = matrix['arr_4']\n",
    "test_Y = matrix['arr_5']\n",
    "\n",
    "train = (train_X, train_Y)\n",
    "test = (test_X, test_Y)\n",
    "\n",
    "# n-gram\n",
    "matrix_ngram = np.load('.\\data\\matrix_n_gram_2.npz')\n",
    "\n",
    "g_train_X = matrix_ngram['arr_0']\n",
    "g_train_Y = matrix_ngram['arr_1']\n",
    "g_valid_X = matrix_ngram['arr_2']\n",
    "g_valid_Y = matrix_ngram['arr_3']\n",
    "g_test_X = matrix_ngram['arr_4']\n",
    "g_test_Y = matrix_ngram['arr_5']\n",
    "\n",
    "g_train = (g_train_X, g_train_Y)\n",
    "g_test = (g_test_X, g_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13eb7c-a0b5-43bc-a247-36b0296656ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 词袋特征--模型向量\n",
    "# 测试参数更新策略对训练效果的影响\n",
    "# 使用SGD\n",
    "loss = []\n",
    "lrs = [0.1, 0.01, 0.001, 0.0001]\n",
    "for lr in lrs:\n",
    "    _, losses = model(train, test, num_epochs=300, batch_size=64, learning_rate=lr, belta1 = 0.9, belta2 = 0.999, epsilon = 1e-8, lamda=0, if_print=False)\n",
    "    loss.append(losses)\n",
    "\n",
    "line = ['-', '--', '-.', ':']\n",
    "color = ['red', 'blue', 'green', 'skyblue']\n",
    "plt.figure()\n",
    "plt.title(\"Different Learning Rates\",fontsize = 24)\n",
    "plt.ylabel(\"Loss\",fontsize = 14)\n",
    "plt.xlabel(\"ten epochs\",fontsize = 14)\n",
    "for i in range(4):\n",
    "    plt.plot(loss[i], color=color[i], linestyle=line[i], label=f'learning_rate={lrs[i]}')\n",
    "plt.legend()\n",
    "plt.savefig('.\\\\data\\\\test_bag_of_word_sgd.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c82b68-0cb4-4cfa-aa35-aa455b5395a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Adam\n",
    "loss = []\n",
    "lrs = [0.1, 0.01, 0.001, 0.0001]\n",
    "for lr in lrs:\n",
    "    _, losses = model(train, test, num_epochs=300, batch_size=64, learning_rate=lr, belta1 = 0.9, belta2 = 0.999, epsilon = 1e-8, lamda=0, opt='Adam', if_print=False)\n",
    "    loss.append(losses)\n",
    "\n",
    "line = ['-', '--', '-.', ':']\n",
    "color = ['red', 'blue', 'green', 'skyblue']\n",
    "plt.figure()\n",
    "plt.title(\"Different Learning Rates\",fontsize = 24)\n",
    "plt.ylabel(\"Loss\",fontsize = 14)\n",
    "plt.xlabel(\"ten epochs\",fontsize = 14)\n",
    "for i in range(4):\n",
    "    plt.plot(loss[i], color=color[i], linestyle=line[i], label=f'learning_rate={lrs[i]}')\n",
    "plt.legend()\n",
    "plt.savefig('.\\\\data\\\\test_bag_of_word_adam.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ddd662-c5fb-493a-a271-1100cbb7de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram特征--模型向量\n",
    "# 测试参数更新策略对训练效果的影响\n",
    "# 使用SGD\n",
    "loss = []\n",
    "lrs = [0.1, 0.01, 0.001, 0.0001]\n",
    "for lr in lrs:\n",
    "    _, losses = model(g_train, g_test, num_epochs=150, batch_size=64, learning_rate=lr, belta1 = 0.9, belta2 = 0.999, epsilon = 1e-8, lamda=0, if_print=False)\n",
    "    loss.append(losses)\n",
    "\n",
    "line = ['-', '--', '-.', ':']\n",
    "color = ['red', 'blue', 'green', 'skyblue']\n",
    "plt.figure()\n",
    "plt.title(\"Different Learning Rates\",fontsize = 24)\n",
    "plt.ylabel(\"Loss\",fontsize = 14)\n",
    "plt.xlabel(\"ten epochs\",fontsize = 14)\n",
    "for i in range(4):\n",
    "    plt.plot(loss[i], color=color[i], linestyle=line[i], label=f'learning_rate={lrs[i]}')\n",
    "plt.legend()\n",
    "plt.savefig('.\\\\data\\\\ngram_sgd.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971bdab0-978d-49fc-bb21-127a097dde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "lrs = [0.1, 0.01, 0.001, 0.0001]\n",
    "for lr in lrs:\n",
    "    _, losses = model(g_train, g_test, num_epochs=150, batch_size=64, learning_rate=lr, belta1 = 0.9, belta2 = 0.999, epsilon = 1e-8, lamda=0, opt='Adam', if_print=False)\n",
    "    loss.append(losses)\n",
    "\n",
    "line = ['-', '--', '-.', ':']\n",
    "color = ['red', 'blue', 'green', 'skyblue']\n",
    "plt.figure()\n",
    "plt.title(\"Different Learning Rates\",fontsize = 24)\n",
    "plt.ylabel(\"Loss\",fontsize = 14)\n",
    "plt.xlabel(\"ten epochs\",fontsize = 14)\n",
    "for i in range(4):\n",
    "    plt.plot(loss[i], color=color[i], linestyle=line[i], label=f'learning_rate={lrs[i]}')\n",
    "plt.legend()\n",
    "plt.savefig('.\\\\data\\\\ngram_adam.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34c430-5e94-4341-b1da-ed7adef66a03",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb63e7d-4057-4d14-b3cb-73410e9abd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set((1, 2, 3))\n",
    "b= set((2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b3deaef-3d4b-4d9b-98a6-ed71f1536195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a|b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c22b3702-ec37-4895-a16a-4fe5fc27c57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('明', '天')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(\"明天\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81b2a6-609b-4dbf-a36e-d15e405dbbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shanqing",
   "language": "python",
   "name": "shanqing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
